# cloudbuild.yaml for sc-pipeline - SIMPLE VERSION
options:
  logging: CLOUD_LOGGING_ONLY
  substitution_option: ALLOW_LOOSE
  
substitutions:
  _REGION: us-central1
  _REPO: services           
  _BUCKET: ${PROJECT_ID}-dataflow
  
steps:
# 0) Make sure the Dataflow bucket exists
- name: gcr.io/google.com/cloudsdktool/cloud-sdk:latest
  entrypoint: bash
  args: 
    - '-c'
    - |
      echo "Checking if bucket gs://${_BUCKET} exists..."
      if ! gsutil ls gs://${_BUCKET} >/dev/null 2>&1; then
        echo "Creating bucket gs://${_BUCKET}..."
        gsutil mb -l ${_REGION} gs://${_BUCKET}
      else
        echo "Bucket already exists"
      fi

# 1) Build image
- name: gcr.io/cloud-builders/docker:latest
  args:
    - 'build'
    - '-t'
    - 'us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:latest'
    - '-t'
    - 'us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:${SHORT_SHA}'
    - '.'

# 2) Push image
- name: gcr.io/cloud-builders/docker:latest
  args:
    - 'push'
    - 'us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:latest'
- name: gcr.io/cloud-builders/docker:latest
  args:
    - 'push'
    - 'us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:${SHORT_SHA}'

# 3) Build the Dataflow Flex Template spec in GCS
- name: gcr.io/google.com/cloudsdktool/cloud-sdk:latest
  entrypoint: bash
  args:
    - '-c'
    - |
      echo "Building Dataflow Flex Template..."
      gcloud dataflow flex-template build gs://${_BUCKET}/templates/sc-pipeline.json \
        --image=us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:latest \
        --sdk-language=PYTHON \
        --metadata-file=metadata.json \
        --project=${PROJECT_ID}

# 4) Verify template creation
- name: gcr.io/google.com/cloudsdktool/cloud-sdk:latest
  entrypoint: bash
  args:
    - '-c'
    - |
      echo "Verifying template was created..."
      gsutil ls -la gs://${_BUCKET}/templates/sc-pipeline.json

# 5) Run the pipeline - HARDCODED VALUES
- name: gcr.io/google.com/cloudsdktool/cloud-sdk:latest
  entrypoint: bash
  args:
    - '-c'
    - |
      echo "Starting Dataflow pipeline..."
      
      gcloud dataflow flex-template run sc-pipeline-20250107-001 \
        --region=us-central1 \
        --template-file-gcs-location=gs://${_BUCKET}/templates/sc-pipeline.json \
        --network=default \
        --subnetwork=regions/us-central1/subnetworks/default \
        --max-workers=10 \
        --parameters="project=${PROJECT_ID},region=us-central1,supplier_sub=projects/${PROJECT_ID}/subscriptions/supplier.sub,material_sub=projects/${PROJECT_ID}/subscriptions/material.sub,plant_sub=projects/${PROJECT_ID}/subscriptions/plant.sub,redis_host=REDIS_HOST_HERE,id_service_url=ID_SERVICE_URL_HERE/id,bq_supplier_bronze=${PROJECT_ID}:domain_bronze.supplier_bronze,bq_material_bronze=${PROJECT_ID}:domain_bronze.material_bronze,bq_plant_bronze=${PROJECT_ID}:domain_bronze.plant_bronze,bq_supplier_dlq=${PROJECT_ID}:domain_bronze.supplier_dlq,bq_material_dlq=${PROJECT_ID}:domain_bronze.material_dlq,bq_plant_dlq=${PROJECT_ID}:domain_bronze.plant_dlq,gcs_temp=gs://${_BUCKET}/bqtmp,adb_host=ADB_HOST_HERE,adb_port=5432,adb_user=postgres,adb_password=Str0ngP@ss!,adb_db=supplychain"
      
      echo "Pipeline started successfully!"

timeout: 1800s
