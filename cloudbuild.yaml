# cloudbuild.yaml  (for sc-pipeline)
options:
  logging: CLOUD_LOGGING_ONLY

substitutions:
  _REGION: us-central1
  _REPO: services                     # Artifact Registry repo name (lowercase)
  _TEMPLATE_PATH: gs://$PROJECT_ID-dataflow/templates/sc-pipeline.json

steps:
# 0) Ensure the Dataflow bucket exists (idempotent)
- name: gcr.io/google.com/cloudsdktool/cloud-sdk
  entrypoint: bash
  args:
    - -lc
    - |
      gsutil ls gs://$PROJECT_ID-dataflow || gsutil mb -l $_REGION gs://$PROJECT_ID-dataflow

# 1) Build the image (note: no nested substitutions)
- name: gcr.io/cloud-builders/docker
  args:
    [
      "build",
      "-t","us-central1-docker.pkg.dev/$PROJECT_ID/$_REPO/sc-pipeline:latest",
      "."
    ]

# 2) Push the image
- name: gcr.io/cloud-builders/docker
  args: ["push","us-central1-docker.pkg.dev/$PROJECT_ID/$_REPO/sc-pipeline:latest"]

# 3) Build the Flex Template JSON into GCS
- name: gcr.io/google.com/cloudsdktool/cloud-sdk
  entrypoint: gcloud
  args:
    [
      "dataflow","flex-template","build","$_TEMPLATE_PATH",
      "--image","us-central1-docker.pkg.dev/$PROJECT_ID/$_REPO/sc-pipeline:latest",
      "--sdk-language","PYTHON",
      "--metadata-file","metadata.json"
    ]


