# cloudbuild.yaml - BUILD TEMPLATE ONLY (no job execution)
options:
  logging: CLOUD_LOGGING_ONLY
  substitution_option: ALLOW_LOOSE
  
substitutions:
  _REGION: us-central1
  _REPO: services           
  _BUCKET: ${PROJECT_ID}-dataflow
  
steps:
# 0) Make sure the Dataflow bucket exists
- name: gcr.io/google.com/cloudsdktool/cloud-sdk:latest
  entrypoint: bash
  args: 
    - '-c'
    - |
      echo "Checking if bucket gs://${_BUCKET} exists..."
      if ! gsutil ls gs://${_BUCKET} >/dev/null 2>&1; then
        echo "Creating bucket gs://${_BUCKET}..."
        gsutil mb -l ${_REGION} gs://${_BUCKET}
      else
        echo "Bucket already exists"
      fi

# 1) Create Artifact Registry repo if it doesn't exist
- name: gcr.io/google.com/cloudsdktool/cloud-sdk:latest
  entrypoint: bash
  args:
    - '-c'
    - |
      echo "Checking if Artifact Registry repo exists..."
      if ! gcloud artifacts repositories describe ${_REPO} --location=${_REGION} >/dev/null 2>&1; then
        echo "Creating Artifact Registry repository..."
        gcloud artifacts repositories create ${_REPO} --repository-format=docker --location=${_REGION}
      else
        echo "Repository already exists"
      fi

# 2) Build image
- name: gcr.io/cloud-builders/docker:latest
  args:
    - 'build'
    - '-t'
    - 'us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:latest'
    - '-t'
    - 'us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:${SHORT_SHA}'
    - '.'

# 3) Push image
- name: gcr.io/cloud-builders/docker:latest
  args:
    - 'push'
    - 'us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:latest'
- name: gcr.io/cloud-builders/docker:latest
  args:
    - 'push'
    - 'us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:${SHORT_SHA}'

# 4) Build the Dataflow Flex Template spec in GCS
- name: gcr.io/google.com/cloudsdktool/cloud-sdk:latest
  entrypoint: bash
  args:
    - '-c'
    - |
      echo "Building Dataflow Flex Template..."
      gcloud dataflow flex-template build gs://${_BUCKET}/templates/sc-pipeline.json \
        --image=us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:latest \
        --sdk-language=PYTHON \
        --metadata-file=metadata.json \
        --project=${PROJECT_ID}

# 5) Verify template creation
- name: gcr.io/google.com/cloudsdktool/cloud-sdk:latest
  entrypoint: bash
  args:
    - '-c'
    - |
      echo "Verifying template was created..."
      gsutil ls -la gs://${_BUCKET}/templates/sc-pipeline.json
      echo ""
      echo "=== TEMPLATE BUILD COMPLETE ==="
      echo "Template location: gs://${_BUCKET}/templates/sc-pipeline.json"
      echo "Docker image: us-central1-docker.pkg.dev/${PROJECT_ID}/${_REPO}/sc-pipeline:latest"
      echo ""
      echo "To run the pipeline manually, use:"
      echo "gcloud dataflow flex-template run JOB_NAME \\"
      echo "  --region=${_REGION} \\"
      echo "  --template-file-gcs-location=gs://${_BUCKET}/templates/sc-pipeline.json \\"
      echo "  --parameters=\"project=${PROJECT_ID},region=${_REGION},...\""

# NO JOB EXECUTION STEP - will run this manually from Cloud Shell

timeout: 1800s
